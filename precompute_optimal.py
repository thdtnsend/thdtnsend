# precompute_optimal.py - ì‹¤ì œ ê¶Œì¥ëŸ‰ ì¡´ì¬ ì¡°í•©ë§Œ ê³„ì‚° + ì˜ˆìƒì‹œê°„ ì¶œë ¥

import os
import json
import itertools
import pandas as pd
from data_loader import load_all_data
from utils import extract_unique_nutrients
from multiprocessing import Pool, cpu_count, current_process
from tqdm import tqdm
import time

# ë°ì´í„° ë¡œë“œ
products_df, recommendations_df, mapping_df = load_all_data()
CACHE_DIR = "cache"
os.makedirs(CACHE_DIR, exist_ok=True)

# ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì„±ë³„+ë‚˜ì´ ì¡°í•©ë§Œ ì‚¬ìš©
valid_pairs = recommendations_df[['ì„±ë³„', 'ë‚˜ì´']].drop_duplicates().dropna()
nutrients = extract_unique_nutrients(recommendations_df)

def get_optimal_combinations(sex, age, max_combinations=10000, top_n=10):
    req_df = recommendations_df[
        (recommendations_df['ì„±ë³„'].astype(str).str.strip() == sex) &
        (recommendations_df['ë‚˜ì´'].astype(str).str.strip() == age)
    ]
    if req_df.empty:
        return [{'ì¶”ì²œ': 'í•´ë‹¹ ì¡°ê±´ì˜ ê¶Œì¥ëŸ‰ ë°ì´í„° ì—†ìŒ'}], {}

    indices = products_df.index
    all_results = []

    for r in range(1, 5):
        combos = list(itertools.combinations(indices, r))
        print(f"[{sex}_{age}] {r}ê°œ ì¡°í•© ìˆ˜: {len(combos):,}ê°œ â†’ ìƒí•œ {max_combinations:,} ì ìš©")
        if len(combos) > max_combinations:
            combos = combos[:max_combinations]

        scored = []
        for i, combo in enumerate(combos):
            sub = products_df.loc[list(combo)].fillna(0)
            price = sub['1ì •ê°€ê²© (ì›)'].sum()

            total = {}
            for _, row in mapping_df.iterrows():
                col, std = row['ì œí’ˆDB_ì—´ì´ë¦„'], row['í‘œì¤€ì„±ë¶„ëª…']
                if col in sub.columns:
                    val = sub[col].sum()
                    if 'mg' in col: val *= 1000
                    total[std] = float(val)

            satisfied = 0
            over = False
            error = 0
            for nut in nutrients:
                req = req_df[req_df['ì„±ë¶„ëª…'].str.contains(f'{nut}.*ê¶Œì¥')]
                limit = req_df[req_df['ì„±ë¶„ëª…'].str.contains(f'{nut}.*ìƒí•œ')]
                req_v = req['ì„­ì·¨ëŸ‰'].values[0] if not req.empty else None
                lim_v = limit['ì„­ì·¨ëŸ‰'].values[0] if not limit.empty else None
                cur = total.get(nut, 0)
                if lim_v and cur > lim_v:
                    over = True
                    break
                if req_v and cur >= req_v:
                    satisfied += 1
                    error += abs(cur - req_v)

            if not over:
                scored.append((satisfied, error, combo, total, float(price), r))

        scored.sort(key=lambda x: (-x[0], x[1]))
        top_results = scored[:top_n]
        all_results.extend(top_results)

    if not all_results:
        return [{'ì¶”ì²œ': 'ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¡°í•©ì´ ì—†ìŠµë‹ˆë‹¤.'}], {}

    results = []
    for i, (satisfied, error, combo, total, price, r) in enumerate(all_results):
        results.append({
            'ì¶”ì²œì¡°í•©': f'{r}ê°œ ì¶”ì²œ #{i + 1}',
            'ì œí’ˆë“¤': products_df.loc[list(combo)].astype(object).to_dict(orient='records'),
            'ì„­ì·¨í•©ê³„': total,
            'ì´ê°€ê²©': price
        })
    return results, {'ì´í•©ì‚°': total}

def process_one_case(args):
    sex, age = args
    case_label = f"{sex}_{age}"
    start = time.time()
    results, comparison = get_optimal_combinations(sex, age)
    out_path = os.path.join(CACHE_DIR, f"{case_label}.json")
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump({"results": results, "comparison_map": comparison}, f, ensure_ascii=False, indent=2)
    elapsed = time.time() - start
    return case_label, elapsed

if __name__ == "__main__":
    from multiprocessing import get_context

    all_cases = [(row['ì„±ë³„'], row['ë‚˜ì´']) for _, row in valid_pairs.iterrows()]
    total_cases = len(all_cases)

    print(f"ğŸ”„ ì´ {total_cases}ê°œì˜ ìœ íš¨ ì¡°í•©ì— ëŒ€í•´ ìºì‹œ ìƒì„± ì‹œì‘í•©ë‹ˆë‹¤...\n")
    total_time = 0

    with get_context("spawn").Pool(processes=min(cpu_count(), 8)) as pool:
        with tqdm(total=total_cases, desc="ì§„í–‰ë¥ ", ncols=100) as pbar:
            for result, elapsed in pool.imap_unordered(process_one_case, all_cases):
                pbar.set_description(f"ìƒì„± ì¤‘: {result}")
                pbar.set_postfix_str(f"{elapsed:.1f}s")
                pbar.update(1)
                total_time += elapsed

    avg_time = total_time / total_cases if total_cases else 0
    print(f"\nğŸ‰ ì „ì²´ ìºì‹œ ìƒì„± ì™„ë£Œ! í‰ê·  ì‹œê°„: {avg_time:.1f}ì´ˆ Ã— {total_cases}ê°œ â‰ˆ {total_time/60:.1f}ë¶„")
